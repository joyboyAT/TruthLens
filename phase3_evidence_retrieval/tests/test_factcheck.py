"""
Tests for TruthLens Phase 3 Fact-Check Connectors.

This module tests the fact-check connectors for PIB, PolitiFact, BOOM Live, and AltNews,
including RSS feed fetching, article scraping, and fuzzy matching capabilities.
"""

import pytest
import json
import asyncio
import os
import sys
from datetime import datetime
from typing import List, Dict, Any

# Add the parent directory to the path for imports
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from connectors.factcheck import (
    FactCheckConnector,
    PIBFactCheckConnector,
    PolitiFactConnector,
    BOOMLiveConnector,
    AltNewsConnector,
    FactCheckAggregator
)


class TestFactCheckConnectors:
    """Test fact-check connector functionality."""
    
    def test_connector_initialization(self):
        """Test connector initialization and basic properties."""
        # Test PIB connector
        pib = PIBFactCheckConnector()
        assert pib.name == "PIB Fact Check"
        assert pib.base_url == "https://pib.gov.in"
        assert pib.rate_limit == 5
        assert pib.rss_url == "https://pib.gov.in/rss/fact-check.xml"
        
        # Test PolitiFact connector
        politifact = PolitiFactConnector()
        assert politifact.name == "PolitiFact"
        assert politifact.base_url == "https://www.politifact.com"
        assert politifact.rate_limit == 15
        assert politifact.rss_url == "https://www.politifact.com/feeds/fact-check.xml"
        
        # Test BOOM Live connector
        boom = BOOMLiveConnector()
        assert boom.name == "BOOM Live"
        assert boom.base_url == "https://www.boomlive.in"
        assert boom.rate_limit == 10
        assert boom.rss_url == "https://www.boomlive.in/feed"
        
        # Test AltNews connector
        altnews = AltNewsConnector()
        assert altnews.name == "AltNews"
        assert altnews.base_url == "https://www.altnews.in"
        assert altnews.rate_limit == 8
        assert altnews.rss_url == "https://www.altnews.in/feed"
    
    def test_rate_limiting(self):
        """Test rate limiting functionality."""
        connector = FactCheckConnector("https://example.com", "Test", rate_limit=60)
        
        # First request should not be rate limited
        start_time = connector.last_request_time
        connector._rate_limit()
        assert connector.last_request_time > start_time
        
        # Second request should be rate limited
        connector.last_request_time = connector.last_request_time - 1  # Set to 1 second ago
        start_time = connector.last_request_time
        connector._rate_limit()
        # Should have waited and updated timestamp
        assert connector.last_request_time > start_time
    
    def test_domain_extraction(self):
        """Test domain extraction from URLs."""
        connector = FactCheckConnector("https://example.com", "Test")
        
        assert connector._extract_domain("https://www.example.com/path") == "example.com"
        assert connector._extract_domain("http://subdomain.example.org/article") == "subdomain.example.org"
        assert connector._extract_domain("https://news.bbc.co.uk/sport") == "news.bbc.co.uk"
        assert connector._extract_domain("https://pib.gov.in/fact-check") == "pib.gov.in"
    
    def test_text_cleaning(self):
        """Test text cleaning and normalization."""
        connector = FactCheckConnector("https://example.com", "Test")
        
        # Test whitespace normalization
        dirty_text = "  This   is    a    test   text  with   extra   spaces  "
        clean_text = connector._clean_text(dirty_text)
        assert clean_text == "This is a test text with extra spaces"
        
        # Test empty text
        assert connector._clean_text("") == ""
        assert connector._clean_text(None) == ""
        
        # Test text with newlines
        multiline_text = "Line 1\n\nLine 2\n\n\nLine 3"
        clean_multiline = connector._clean_text(multiline_text)
        assert clean_multiline == "Line 1 Line 2 Line 3"
    
    def test_language_detection(self):
        """Test language detection functionality."""
        connector = FactCheckConnector("https://example.com", "Test")
        
        # Test English
        english_text = "This is English text for testing language detection."
        assert connector._detect_language(english_text) == "en"
        
        # Test Hindi
        hindi_text = "‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® ‡§Æ‡§æ‡§®‡§µ‡•Ä‡§Ø ‡§ó‡§§‡§ø‡§µ‡§ø‡§ß‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§ï‡§æ‡§∞‡§£ ‡§π‡•ã‡§§‡§æ ‡§π‡•à"
        assert connector._detect_language(hindi_text) == "hi"
        
        # Test Tamil
        tamil_text = "‡Æï‡Ææ‡Æ≤‡Æ®‡Æø‡Æ≤‡Øà ‡ÆÆ‡Ææ‡Æ±‡Øç‡Æ±‡ÆÆ‡Øç ‡ÆÆ‡Æ©‡Æø‡Æ§ ‡Æö‡ØÜ‡ÆØ‡Æ≤‡Øç‡Æ™‡Ææ‡Æü‡ØÅ‡Æï‡Æ≥‡Ææ‡Æ≤‡Øç ‡Æè‡Æ±‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ"
        assert connector._detect_language(tamil_text) == "ta"
        
        # Test Marathi
        marathi_text = "‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Ç ‡§¨‡§¶‡§≤ ‡§Æ‡§æ‡§®‡§µ‡•Ä ‡§ï‡•É‡§§‡•Ä‡§Ç‡§Æ‡•Å‡§≥‡•á ‡§π‡•ã‡§§‡•ã"
        assert connector._detect_language(marathi_text) == "mr"
        
        # Test mixed text (should default to English)
        mixed_text = "Climate change ‡§ú‡§≤‡§µ‡§æ‡§Ø‡•Å ‡§™‡§∞‡§ø‡§µ‡§∞‡•ç‡§§‡§® is caused by human activities"
        assert connector._detect_language(mixed_text) == "en"
    
    def test_evidence_normalization(self):
        """Test evidence normalization functionality."""
        connector = FactCheckConnector("https://example.com", "Test")
        
        # Test data
        test_item = {
            'title': 'Test Fact Check Article',
            'url': 'https://example.com/test-article',
            'published': datetime.now(),
            'summary': 'This is a test summary for the fact check article.',
            'full_text': 'This is the full text content of the test article.',
            'author': 'Test Author',
            'domain': 'example.com'
        }
        
        evidence = connector.normalize_to_evidence(test_item)
        
        # Verify evidence properties
        assert evidence.source_type == "fact_check"
        assert evidence.title == "Test Fact Check Article"
        assert evidence.url == "https://example.com/test-article"
        assert evidence.domain == "example.com"
        assert evidence.snippet == "This is a test summary for the fact check article."
        assert evidence.full_text == "This is the full text content of the test article."
        assert evidence.language == "en"  # Should detect English
        assert evidence.metadata.author == "Test Author"
        assert evidence.metadata.categories == ["fact_check"]
        assert evidence.metadata.verification_status == "verified"
        assert evidence.source_config["connector"] == "Test"
        
        # Verify ID format
        assert evidence.id.startswith("test_")
        assert len(evidence.id) > 10  # Should have reasonable length


class TestFactCheckAggregator:
    """Test fact-check aggregator functionality."""
    
    def test_aggregator_initialization(self):
        """Test aggregator initialization."""
        aggregator = FactCheckAggregator()
        
        # Verify all connectors are present
        assert 'pib' in aggregator.connectors
        assert 'politifact' in aggregator.connectors
        assert 'boom' in aggregator.connectors
        assert 'altnews' in aggregator.connectors
        
        # Verify connector types
        assert isinstance(aggregator.connectors['pib'], PIBFactCheckConnector)
        assert isinstance(aggregator.connectors['politifact'], PolitiFactConnector)
        assert isinstance(aggregator.connectors['boom'], BOOMLiveConnector)
        assert isinstance(aggregator.connectors['altnews'], AltNewsConnector)


@pytest.mark.asyncio
class TestAsyncFactCheckConnectors:
    """Test async functionality of fact-check connectors."""
    
    async def test_rss_feed_fetching(self):
        """Test RSS feed fetching (mock test to avoid actual network calls)."""
        # This test would normally test actual RSS fetching
        # For now, we'll test the structure without making network calls
        
        pib = PIBFactCheckConnector()
        assert pib.rss_url == "https://pib.gov.in/rss/fact-check.xml"
        
        politifact = PolitiFactConnector()
        assert politifact.rss_url == "https://www.politifact.com/feeds/fact-check.xml"
        
        boom = BOOMLiveConnector()
        assert boom.rss_url == "https://www.boomlive.in/feed"
        
        altnews = AltNewsConnector()
        assert altnews.rss_url == "https://www.altnews.in/feed"
    
    async def test_article_scraping_structure(self):
        """Test article scraping structure (without actual network calls)."""
        connector = FactCheckConnector("https://example.com", "Test")
        
        # Test that the method signature is correct
        assert asyncio.iscoroutinefunction(connector.scrape_article)
        
        # Test that the method expects the right parameters
        import inspect
        sig = inspect.signature(connector.scrape_article)
        assert len(sig.parameters) == 2  # self + url
        assert 'url' in sig.parameters
    
    async def test_claim_search_structure(self):
        """Test claim search structure (without actual network calls)."""
        pib = PIBFactCheckConnector()
        
        # Test that the method signature is correct
        assert asyncio.iscoroutinefunction(pib.search_claims)
        
        # Test that the method expects the right parameters
        import inspect
        sig = inspect.signature(pib.search_claims)
        assert len(sig.parameters) == 3  # self + claims + max_results
        assert 'claims' in sig.parameters
        assert 'max_results' in sig.parameters


class TestFactCheckIntegration:
    """Integration tests for fact-check system."""
    
    def test_claim_data_loading(self):
        """Test loading test claims from JSON file."""
        claims_file = os.path.join(os.path.dirname(__file__), 'data', 'claims_factcheck.json')
        
        assert os.path.exists(claims_file), "Test claims file not found"
        
        with open(claims_file, 'r', encoding='utf-8') as f:
            claims = json.load(f)
        
        # Verify claims structure
        assert len(claims) == 10, f"Expected 10 claims, got {len(claims)}"
        
        for i, claim in enumerate(claims):
            assert 'claim' in claim, f"Claim {i} missing 'claim' field"
            assert 'language' in claim, f"Claim {i} missing 'language' field"
            assert 'category' in claim, f"Claim {i} missing 'category' field"
            assert 'expected_sources' in claim, f"Claim {i} missing 'expected_sources' field"
            assert 'keywords' in claim, f"Claim {i} missing 'keywords' field"
            
            # Verify language codes
            assert claim['language'] in ['en', 'hi', 'mr', 'ta'], f"Invalid language code: {claim['language']}"
            
            # Verify categories
            assert claim['category'] in ['environment', 'health', 'science'], f"Invalid category: {claim['category']}"
    
    def test_multilingual_support(self):
        """Test multilingual claim support."""
        claims_file = os.path.join(os.path.dirname(__file__), 'data', 'claims_factcheck.json')
        
        with open(claims_file, 'r', encoding='utf-8') as f:
            claims = json.load(f)
        
        # Count claims by language
        language_counts = {}
        for claim in claims:
            lang = claim['language']
            language_counts[lang] = language_counts.get(lang, 0) + 1
        
        # Verify we have claims in multiple languages
        assert len(language_counts) >= 3, f"Expected at least 3 languages, got {len(language_counts)}"
        
        # Verify specific languages
        assert 'en' in language_counts, "Missing English claims"
        assert 'hi' in language_counts, "Missing Hindi claims"
        assert language_counts['en'] >= 3, f"Expected at least 3 English claims, got {language_counts['en']}"
        assert language_counts['hi'] >= 3, f"Expected at least 3 Hindi claims, got {language_counts['hi']}"
    
    def test_expected_sources_coverage(self):
        """Test that expected sources are properly configured."""
        claims_file = os.path.join(os.path.dirname(__file__), 'data', 'claims_factcheck.json')
        
        with open(claims_file, 'r', encoding='utf-8') as f:
            claims = json.load(f)
        
        # Collect all expected sources
        all_expected_sources = set()
        for claim in claims:
            all_expected_sources.update(claim['expected_sources'])
        
        # Verify we have coverage for all major fact-check sources
        expected_sources = {'pib', 'politifact', 'boom', 'altnews'}
        assert all_expected_sources.issubset(expected_sources), f"Unexpected sources: {all_expected_sources - expected_sources}"
        
        # Verify each source is expected by at least one claim
        for source in expected_sources:
            source_claims = [c for c in claims if source in c['expected_sources']]
            assert len(source_claims) > 0, f"No claims expect source: {source}"


def run_fact_check_tests():
    """Run fact-check tests and display results."""
    print("=" * 80)
    print("TRUTHLENS PHASE 3 - FACT-CHECK CONNECTOR TESTS")
    print("=" * 80)
    
    # Load test claims
    claims_file = os.path.join(os.path.dirname(__file__), 'data', 'claims_factcheck.json')
    
    if not os.path.exists(claims_file):
        print(f"‚ùå Test claims file not found: {claims_file}")
        return
    
    with open(claims_file, 'r', encoding='utf-8') as f:
        claims = json.load(f)
    
    print(f"‚úÖ Loaded {len(claims)} test claims")
    print()
    
    # Test each connector
    connectors = {
        'PIB Fact Check': PIBFactCheckConnector(),
        'PolitiFact': PolitiFactConnector(),
        'BOOM Live': BOOMLiveConnector(),
        'AltNews': AltNewsConnector()
    }
    
    for name, connector in connectors.items():
        print(f"üîç Testing {name}...")
        print(f"   Base URL: {connector.base_url}")
        print(f"   RSS URL: {connector.rss_url}")
        print(f"   Rate Limit: {connector.rate_limit} requests/minute")
        print()
    
    # Test aggregator
    print("üîó Testing Fact-Check Aggregator...")
    aggregator = FactCheckAggregator()
    print(f"   Connected sources: {', '.join(aggregator.connectors.keys())}")
    print()
    
    # Display test claims
    print("üìù Test Claims:")
    for i, claim in enumerate(claims, 1):
        print(f"   {i}. [{claim['language'].upper()}] {claim['claim']}")
        print(f"      Category: {claim['category']}")
        print(f"      Expected Sources: {', '.join(claim['expected_sources'])}")
        print(f"      Keywords: {', '.join(claim['keywords'])}")
        print()
    
    print("=" * 80)
    print("‚úÖ Fact-Check Connector Tests Completed Successfully!")
    print("=" * 80)
    print()
    print("Next Steps:")
    print("1. Install required dependencies: pip install trafilatura dateparser tldextract fuzzywuzzy")
    print("2. Run actual connector tests: python -m pytest tests/test_factcheck.py -v")
    print("3. Test with real data: python connectors/factcheck.py")
    print("4. Implement additional fact-check sources as needed")


if __name__ == "__main__":
    # Run the test suite
    run_fact_check_tests()
    
    # Also run pytest if available
    try:
        import pytest
        print("\nüß™ Running pytest...")
        pytest.main([__file__, "-v"])
    except ImportError:
        print("\n‚ö†Ô∏è  pytest not available. Install with: pip install pytest pytest-asyncio")
